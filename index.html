<!DOCTYPE html>
<html>
<head>
    <title>MediaPipe Object Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision"></script>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    
    <p id="cupInfo">ì»µ: ì—†ìŒ</p>
    <p id="personInfo">ì‚¬ëŒ: ì—†ìŒ</p>

    <script>
        async function startTracking() {
            const video = document.getElementById("video");
            const canvas = document.getElementById("canvas");
            const ctx = canvas.getContext("2d");
            const cupInfo = document.getElementById("cupInfo");
            const personInfo = document.getElementById("personInfo");

            // ì¹´ë©”ë¼ ì„¤ì •
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;

            // MediaPipe Object Detector ë¡œë“œ (import ì—†ì´ ì‚¬ìš©)
            const { ObjectDetector, FilesetResolver } = window;
            const visionFileset = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm");
            const detector = await ObjectDetector.createFromOptions(visionFileset, {
                baseOptions: { 
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/object_detector/ssd_mobilenet_v2/float32/1/ssd_mobilenet_v2.tflite" 
                },
                runningMode: "VIDEO",  // ğŸ”¹ 'VIDEO' ëª¨ë“œ ì„¤ì •
                scoreThreshold: 0.5
            });

            async function detectObjects() {
                const detections = await detector.detectForVideo(video, performance.now());
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                let foundCup = false;
                let foundPerson = false;
                let cupX = 0, cupY = 0, personX = 0, personY = 0;

                detections.forEach(obj => {
                    console.log("ê°ì§€ëœ ê°ì²´:", obj.categoryName);
                    const targetObjects = ["cup", "person"];

                    if (targetObjects.includes(obj.categoryName)) {
                        const [x, y, width, height] = obj.boundingBox;
                        ctx.strokeStyle = (obj.categoryName === "cup") ? "red" : "blue";
                        ctx.lineWidth = 3;
                        ctx.strokeRect(x, y, width, height);

                        let centerX = x + width / 2;
                        let centerY = y + height / 2;

                        if (obj.categoryName === "cup") {
                            foundCup = true;
                            cupX = Math.round(centerX);
                            cupY = Math.round(centerY);
                        } else if (obj.categoryName === "person") {
                            foundPerson = true;
                            personX = Math.round(centerX);
                            personY = Math.round(centerY);
                        }
                    }
                });

                // ì›¹í˜ì´ì§€ì— ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸
                cupInfo.innerText = foundCup ? `ì»µ: X=${cupX}, Y=${cupY}` : "ì»µ: ì—†ìŒ";
                personInfo.innerText = foundPerson ? `ì‚¬ëŒ: X=${personX}, Y=${personY}` : "ì‚¬ëŒ: ì—†ìŒ";

                // ì•±ì¸ë²¤í„°ë¡œ ë°ì´í„° ì „ì†¡
                window.AppInventor.setWebViewString(`cup,${cupX},${cupY};person,${personX},${personY}`);

                requestAnimationFrame(detectObjects);
            }

            detectObjects();
        }

        startTracking();
    </script>
</body>
</html>
